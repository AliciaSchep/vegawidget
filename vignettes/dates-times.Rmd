---
title: "Work with dates and times"
date: "`r Sys.Date()`"
output: rmarkdown::html_document
---

```{r message=FALSE}
library("vegawidget")
library("conflicted")
library("lubridate")
library("readr")
library("dplyr")
```

Dates and times can be tricky, even in the familiar confines of R. Vega and Vega-Lite are run in JavaScript, which has a different philosophy of dates and times from R. In R, we have access to the entire time-zone database; in JavaScript, using the `Date` object, there are only *two* time zones available: the local time zone used by the client browser and UTC.  

If you are working with time-indexed data, this mismatch of capabilities introduces a lot of "opportunities" for you to create a Vega(-Lite) visualization that does not behave as you intend. The purpose of this article is to walk through the pit-falls of translating dates and times from R to JavaScript, to describe the in-and-outs of Vega-Lite time-units, and to show some useful practices for staying out of trouble.

The documentation for the Altair Python package includes an [article on times and dates](https://altair-viz.github.io/user_guide/times_and_dates.html) with very clear explanations. It is hoped that this article can be similarly clear. 

## Time zones

```{r echo=FALSE}
str_moon_landing <- "1969-07-21T02:56:15Z"
moon_landing <- parse_datetime(str_moon_landing)
```

### Issue

Things happen at fixed instants in time; we use time zones to describe those fixed instants using a local context. Consider that Neil Armstrong's first step on the moon happened at ``r str_moon_landing``, represented here as an ISO-8601 string. This uses UTC, the globally-recognized standard reference-frame; ISO-8601 is the standard way to communicate time-stamps. However, this information lacks context for someone who may remember the instant from Chicago, or another who may remember the *same* instant from Paris.

In the context of Chicago, the first-step happened at ``r with_tz(moon_landing, "America/Chicago")``; in the context of Paris, it happened at ``r with_tz(moon_landing, "Europe/Paris")``. We use a system of time zones to provide this context. The standard representation of time zones is IANA (also known as Olson) time zones. These are each associated with a given geographic region, such as `"America/Chicago"` or `"Europe/Paris"`; a time zone provides an offset to UTC, given an instant expressed in UTC. 

High level-programming languages, such as R, have access to the full IANA time-zone database. However, the JavaScript `Date` object has access to only two time zones: the timezone of the local browser, and UTC. JavaScript-based visualization systems, including d3, Plotly, and Vega, are constrained by this limitation because they depend on the JavaScript `Date` object. 

### Vega-Lite examples

Let's look at an example using one of the datasets included in this package: `data_seattle_hourly`, adapted from [vega-datasets](https://github.com/vega/vega-datasets):

```{r}
data_seattle_hourly
```

This dataset contains hourly observations of Seattle temperature (Â°F) for the year 2010. Let's inspect the time zone of the `date` variable:

```{r}
tz(data_seattle_hourly$date)
```

We see that the `date` variable uses the `"America/Los_Angeles"` time zone, which is what we would expect for Seattle. This means that the values for `date` are displayed above as local time. To make the following demonstrations a little lighter, we will use an shortened version of this dataset, one that uses only 2010-01-01:

```{r}
data_seattle_hourly_short <-
  data_seattle_hourly %>%
  dplyr::filter(
    floor_date(date, "day") == ymd("2010-01-01", tz = "America/Los_Angeles")
  ) %>%
  glimpse()
```

```{r}
spec_local <- 
  list(
    `$schema` = vega_schema(),
    width = 400,
    height = 75,
    data = list(values = data_seattle_hourly_short),
    mark = "line",
    encoding = list(
      x = list(
        field = "date", 
        type = "temporal",
        axis = list(format = "%H:%M")
      ),
      y = list(
        field = "temp", 
        type = "quantitative", 
        scale = list(zero = FALSE)
      )
    )
  ) %>%
  as_vegaspec()

spec_local
```

Our expectation is that this chart will show the times using the local time-zone; in this case, our expectation is met. This is good, but let's have a closer look at what's going on. 

Let's look at first couple of observations in the data frame, as they would be rendered as JSON:

```{r}
data_seattle_hourly_short %>% head(2) %>% jsonlite::toJSON()
```

We see that date-times are *not* formatted using ISO-8601 formatting - the times are serialized to JSON using the local context. When Vega-Lite [parses this data](https://vega.github.io/vega-lite/docs/timeunit.html#utc), it recognizes that this is a datetime and that the format is *not* ISO-8601. As such, these times will be parsed, interpreted, and displayed as local times:

> 1) Times are parsed as UTC time if the date strings are in ISO format. Note that in JavaScript date strings without time are interpreted as UTC but but date strings with time and without timezone as local.
> 2) If that is not the case, by default, times are assumed to be local.

This is all well-and-good, but you should be aware of some "gotchas" due to daylight-saving time:

- In Seattle in 2010, the *local* time represented by `"2010-03-14 02:00:00"` does not exist; the local time represented by `"2010-11-07 01:00:00"` occurs twice. This is the reason that the dataset has 8759 observations rather than our expectation of 8760: the "repeated" hour has only one observation. This is one of the fragilities of storing datetimes using local time rather than UTC.

- In 2010, in Europe, the daylight-saving time transitions happened on different dates from the USA - in Europe this happened on `"2010-03-28"` and `"2010-10-31"`. This means that there are local times represented in this dataset that do not exist in *local* time in Europe, so they will not be parsed, interpreted, or displayed properly.

This is part of the motivation to serialize datetimes using the ISO-8601 format, then to treat the local time-zone, in this case `"America/Los_Angeles"`, as metadata. We will demonstrate, for the reasons outlined in at the beginning of this article, we cannot get this to work as we expect for Vega(-Lite).

Let's start by using a function help us serialize the data:

```{r}
data_seattle_hourly_short_iso <- 
  data_seattle_hourly_short %>%
  vw_serialize_data(iso_dttm = TRUE) %>%
  glimpse()
```

You can see that we have changed the `date` variable from a datetime to a character string. Its values show `date`:

- in the ISO-8601 format (using the `iso_dttm` argument). 
- ISO-8601 implies using UTC (at this time, 8 hours ahead of Seattle). 
- to millisecond precision (matching JavaScript's time-resolution).

Let's see what our chart looks like, using this data:

```{r}
spec_iso_local <- spec_local

spec_iso_local$data$values <- data_seattle_hourly_short_iso

spec_iso_local
```

If the browser you are using to view this page is in the `"America/Los_Angeles"` time zone, this chart will appear identical as above. However, if you are not, the axis labels for `date` are now not what we might expect. Vega-Lite parses and interprets the `date` values as UTC, but displays the `date` using the *browser's* local time-zone. I (Ian) am in the `"America/Chicago"` time zone, so the axis, for me, begins at 02:00. This is consistent with *my* time zone being two hours ahead of `"America/Los_Angeles"`.

As noted above, the JavaScript `Date` object knows two time-zones: the browser's and UTC. Although it will not be terribly satisfying, we can direct Vega-Lite to [display the time as UTC](https://vega.github.io/vega-lite/docs/timeunit.html#output) (this way, everyone can be equally unfulfilled):

```{r}
spec_iso_utc <- spec_iso_local

spec_iso_utc$encoding$x$scale <- list(type = "utc") 

spec_iso_utc
```

Here, the `date` axis begins at 08:00, which is the UTC time when it was midnight in Seattle.

### Datetime compromise

Because of the time-zone limitations of the JavaScript `Date` object, we are forced to make a compromise. 

If we serialize datetimes using the local (to the data) time-zone:

- Vega-Lite parses, interprets, and displays the datetimes as if they are local times in the browser's time zone.
- Different application of daylight-saving time across different time zones are a potential source of error in the visualization.
- The data, as sent to the browser, is incomplete because we have "lost" the link to the actual instants-in-time that the data represents.

In other situations, the best-practice for serializing datetimes is to use ISO-8601 formatting and to keep the time zone as metadata. This allows us to refer, unambiguously, to the actual instants-in-time. In a visualization, we would like to be able to use the time zone to provide the needed context to make aggregations, label axes, etc. 

Here, we do not (yet) have this option. If we serialize datetime data using the ISO-8601 format, the instants are parsed and interpreted correctly. However, we have the option to display using only the timezone of the browser or UTC. It is entirely like that the context (time zone) of our data is different from the context of our browser - in which case we are unable to make an effective visualization.

Faced with this choice, it seems the first option -- serializing our data using the data's local time-zone -- is the least-bad option, as it gives us the opportunity to present the data in context. That being said, we need to be mindful of the daylight-saving pitfalls, and warn our users accordingly. Further, we have to recognize (and possibly note to our users) that the data inside the visualization is compromised. 

### Notes on dates

In R, we have different types for date vs. datetimes. This seems a useful distinction, as it allows us to compare a day in New York with a day in Brisbane. 

When designing a Vega visualization, we have a "trick" we can use to treat all dates regardless of time zone: we can treat dates as the datetime at the start of that day in UTC. Vega [parsing rule](https://vega.github.io/vega-lite/docs/timeunit.html#utc) for datetimes is that if the data is formatted using ISO-8601, then it is parsed as UTC.

Let's consider the dataset `data_seattle_daily`, where we have daily observations of Seattle weather over the course of four years:

```{r}
data_seattle_daily
```

When we serialize this data, it will use the ISO-8601 format for dates, by default. 

In preparation of making some examples, let's filter to keep the first month of the dataset:

```{r}
data_seattle_daily_short <- 
  data_seattle_daily %>%
  dplyr::filter(floor_date(date, "month") == as.Date("2012-01-01")) %>%
  glimpse()
```

Let's look at a line-plot of the daily maximum-temperatures:

```{r}
spec_tempmax_local <- 
  list(
    `$schema` = vega_schema(),
    width = 400,
    height = 75,
    data = list(values = data_seattle_daily_short),
    mark = "line",
    encoding = list(
      x = list(
        field = "date",
        type = "temporal"
      ),
      y = list(
        field = "temp_max",
        type = "quantitative"
      ),
      tooltip = list(
        list(field = "date", type = "temporal", format = "%Y-%m-%d %H:%M:%S")
      )
    )
  ) %>%
  as_vegaspec()

spec_tempmax_local
```

If you are in a timezone that is different from UTC (sorry UK), you will see that the points that make up the line are not aligned with the grid. This is another effect of time zones - Vega has parsed and interpreted the `date` as UTC, but its default is to display it to us using the local time-zone of our browser. For me, near Chicago, the days are "starting" six hours early. You can verify this by using the tooltips, which show the `date` with the time attached.

In this situation, we wish to keep the UTC interpretation throughout the visualization. We can do this by using a UTC scale-specification to the x-axis:

```{r}
spec_tempmax_utc <- spec_tempmax_local

spec_tempmax_utc$encoding$x$scale <- list(type = "utc")
spec_tempmax_utc$encoding$tooltip <- NULL

spec_tempmax_utc
```

By setting the scale to UTC, the axis is aligned properly for everyone.

### Summary

#### Parsing

When Vega(-Lite) parses values for dates and times, it checks whether the string is formatted using [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601). 

Here are some examples of ISO-8601 strings:

```
2001-01-01T19:34:05Z
2001-01-01T19:34:05+05:00
2001-01-01
```

Here are some examples of *non*-ISO-8601 strings:

```
2001-01-01 19:34:05
Jan-01-2001 19:34:05
2001/01/01 
```

By default, if the format is ISO-8601, Vega will parse the string as UTC. Similarly, by default, if the format is non-ISO-8601, Vega will parse the string as local time. You can override the default by providing a [parsing directive](https://vega.github.io/vega-lite/docs/data.html#format) in the specification.
 
Date and datetimes are the same type in JavaScript - a date is just a datetime at the start of a day. For this reason, you may wish to choose different format to serialize dates and datetimes.

#### Datetimes

It is likely that you wish to show datetime values using the context of the data, e.g. you want to look at the temperatures in Seattle using in the context of Seattle. From R, assuming that your datetimes are using the data-local timezone, e.g. `"America/Los_Angeles"`, the least-bad way to do this is to serialize your datetime values using data-local time, rather than using UTC. You can use the `vw_serialize_data()` function to do this. Although this will let you display the data as you intend, there are a couple of important points to keep in mind:

- Weird things may happen at the daylight-saving time transition-points; this problem is doubled if the transistion points are different in the data than they are in the user's browser, e.g. the data's context is in the US and the user's browser is in Europe.

- Your data is now compromised as your datetime strings no longer unabiguously identify the instants in time. Because Vega does not use generic time-zones, anyone who extracts the data from the Vega specification will be lacking the time-zone context.

#### Dates

Dates seeem to have an "international" context, whereas datetimes are thought-of in their local context. As such, you will may want to use the UTC context in Vega - so you would serialize dates using ISO-8601 format. This is the default behavior of the JSON serializer; if you want dates to use a local context, you can use the `vw_serialize_data()` with `iso_date = FALSE`.

Because Vega's default is to show temporal fields using the browser's timezone, you will have to specify a UTC scale. 

#### Scales

In Vega-Lite, displaying temporal-values is a separate activity from parsing temporal-values. Regardless of the parsing behavior, Vega-Lite's default temporal-scale uses the browser's local time-zone. You can specify a scale in an encoding, for example:

```r
list(
  ...,
  encoding = list(
    x = list(field = "date", type = "temporal", scale = list(type = "utc")),
    ...
  ),
  ...
)
```

## Vega-Lite time unit

For an interactive version of this section on time units, please see this [Observable notebook](https://beta.observablehq.com/@ijlyttle/vega-lite-timeunit).

Let's say you have daily weather data for, say, Seattle over the course of four years:

```{r}
data_seattle_daily
```

You already know how to parse and interpret the `date` values, and how to create charts that treat time sequentially. However, you may be interested to:

- aggregate the data by month
- compare the behavior anong the years

You could prepare such variables in a pre-processing step, creating new variables in R, using **dplyr** and **lubridate**. You can also do this in Vega-Lite, using **time unit**, a transformation mechanism for temporal values.

Let's make a specification for a time-based scatterplot for the daily maximum-temperature:

```{r}
spec_daily <-
  list(
    `$schema` = vega_schema(),
    width = 600,
    height = 200,
    data = list(values = data_seattle_daily),
    mark = "point",
    encoding = list(
      x = list(
        field = "date",
        type = "temporal",
        scale = list(type = "utc")
      ),
      y = list(
        field = "temp_max",
        type = "quantitative",
        scale = list(domain = list(-5, 40))
      ),
      tooltip = list(
        list(
          field = "date", 
          type = "temporal", 
          timeUnit = "utcyearmonthdate",
          title = "date",
          format = "%Y-%m-%d"
        ),
        list(field = "temp_max", type = "quantitative")
      )
    )
  ) %>%
  as_vegaspec()

spec_daily
```

There's nothing too surprising here, just to note that we have observations for every day for the calendar years 2102-2015, inclusive.

We use point-marks not because it is optimal for the visualization (it's not), but because it may make clearer what is happening behind the scenes. Seeing what Vega-Lite *actually* does can help us to understand the "time-unit" API.

Let's say we want to look at the maximum temperature by month. If we were to do this in R, we might make a preprocessing step like this:

```{r}
data_seattle_daily %>%
  mutate(yearmonth = floor_date(date, "month")) %>%
  group_by(yearmonth) %>%
  summarise(temp_max = max(temp_max)) %>%
  glimpse()
```

We could then plot this data. However, we can make these data transformations within Vega-Lite. We will show this as a series of steps; the first step is to map the values of `date` to the beginning of the month.

```{r}
# copy the previous spec
spec_yearmonth <- spec_daily

# modify the x-encoding
spec_yearmonth$encoding$x$scale <- NULL
spec_yearmonth$encoding$x$timeUnit <- "utcyearmonth"

# modify the tooltip-encoding
spec_yearmonth$encoding$tooltip <- 
  list(
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyearmonthdate",
      title = "date",
      format = "%Y-%m-%d"
    ),
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyearmonth", 
      title = "yearmonth", 
      format = "%Y-%m-%d"
    ),     
    list(field = "temp_max", type = "quantitative")
  )

spec_yearmonth
```

Let's ignore the tooltip specification for the time being. The main change we made to the specification was to tweak the x-encoding: removing the UTC `scale` and adding a `timeUnit`, setting it to `"utcyearmonth"`. The specification of a time unit did three things:

- It binned the `date` variable by truncating the time to include the year and month, hence the `"yearmonth"` part of the directive. This is equivalent to the dplyr expression `mutate(yearmonth = floor_date(date, "month"))`. 

- Because we parsed `date` as UTC, we use the UTC context to determine "when" each month starts. This is why the time-unit directive starts with `"utc"`.

- It changes the default formatting for the axes to reflect that we have truncated `date` to its year-month.

For me, the essence of the concept is that a **time unit defines a mapping of an existing temporal-variable to a new temporal-variable**; it is a `dplyr::mutate()` that returns another datetime.

We removed the UTC scale from the x-encoding becasue this is taken care-of with the specification of `"utc"` within the time unit. If we were to [specify it twice](https://vega.github.io/vega-lite/docs/timeunit.html#output), the UTC-offset would be applied twice.

We modified the tooltip to demonstrate that we have the same underlying data - on the x-axis, we use the "mutated" year-month rather than the date. 

The next step is to apply the `group_by()` and `summarise()` operations.

```{r}
# copy the previous spec
spec_yearmonth_aggregate <- spec_yearmonth

# add an aggretation directive to the y-encoding
spec_yearmonth_aggregate$encoding$y$aggregate = "max"

# modify the tooltip
spec_yearmonth_aggregate$encoding$tooltip <- 
  list(
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyearmonth", 
      title = "yearmonth", 
      format = "%Y-%m-%d"
    ),     
    list(field = "temp_max", type = "quantitative", aggregate = "max")
  )  

spec_yearmonth_aggregate
```

These two operations are undertaken by adding a single specification: the y-encoding directive `aggregate = "max"`. Vega-Lite carries out an implied `group_by()` on all the encodings are not aggregated. In this case, y (`temp_max`) is aggregated; we group by our remaining encoding, x, which is now the "year-month".

We can add an color-encoding for the year, again using a time-unit:

```{r}
# copy previous spec
spec_yearmonth_aggregate_color <- spec_yearmonth_aggregate

# create encoding for color using "utcyear" time-unit of date
spec_yearmonth_aggregate_color$encoding$color <- 
  list(field = "date", type = "nominal", timeUnit = "utcyear")

# define a tooltip
spec_yearmonth_aggregate_color$encoding$tooltip <- 
  list(
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyear", 
      title = "year", 
      format = "%Y-%m-%d"
    ),  
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyearmonth", 
      title = "yearmonth", 
      format = "%Y-%m-%d"
    ),      
    list(field = "temp_max", type = "quantitative", aggregate = "max")
  ) 

spec_yearmonth_aggregate_color
```

Again, this is another intermediate step; creating a new internal variable using a `"utcyear"` time-unit. We see that Vega-Lite does the "right" thing with the color-legend. Using the tooltip, we also see that the values of `year` are the datetimes corresponding to the first instant in a given year.

In the previous chart, we noted that Vega-Lite will group-by any encoded variable that is not aggregated, then perform the aggregations. In this case, we are grouping by "year" and "year-month", so the end-result of the groupings is the same as the previous example. 

Also, note that we need to take care with our tooltip definitions. Tooltips are encodings, so the aggregation rule applies to tooltip encodings no different that it applies to other encodings. If something "weird" happens when building a chart that uses implicit aggregation, it can be useful to check the tooltip-definitions for encodings and aggregations that are inconsistent with the rest of the encodings (ask me how I found this out).

Our final chart in this series of examples will be to put each of the years on the same scale; we do this by using a time-unit of `"utcmonth"` for the x-encoding. 

```{r}
spec_month_aggregate_color <- spec_yearmonth_aggregate_color

spec_month_aggregate_color$encoding$x$timeUnit <- "utcmonth"

spec_month_aggregate_color$encoding$tooltip <- 
  list(
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcyear", 
      title = "year", 
      format = "%Y-%m-%d"
    ),  
    list(
      field = "date", 
      type = "temporal", 
      timeUnit = "utcmonth", 
      title = "month", 
      format = "%Y-%m-%d"
    ),      
    list(field = "temp_max", type = "quantitative", aggregate = "max")
  ) 

spec_month_aggregate_color
```










